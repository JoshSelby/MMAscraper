<<<<<<< HEAD
if (!require("foreach")) install.packages("foreach")
library(foreach)
if (!require("doSNOW")) install.packages("doSNOW")
library(doSNOW)
if (!require("parallel")) install.packages("parallel")
library(parallel)
if (!require("dplyr")) install.packages("dplyr")
library(dplyr)
fights_table <- readRDS("~/GitHub/MMAscraper/fights_table.rds")
NumberOfCluster <- detectCores()
cl <- makeCluster(NumberOfCluster, outfile="log.txt")
registerDoSNOW(cl)
# Scrapes a single page and creates list
scrape <- function(link) {
if (!require("rvest")) install.packages("rvest")
library(rvest)
if (!require("httr")) install.packages("httr")
library(httr)
if (!require("dplyr")) install.packages("dplyr")
library(dplyr)
if (!require("xml2")) install.packages("xml2")
library(xml2)
# Initialize scraper
searched_links <- c()
links_to_search <- c()
fights_table <- data.frame(matrix(ncol=11,nrow=0))
fn_nn <- list()
no_errors = TRUE
# read the webpage page of the fighter that we are interested in
fighter_page <- tryCatch({
read_html(paste0("http://www.sherdog.com/fighter",link))
},
error=function(cond) {
message(cond)
no_errors = FALSE
return(fighter_page)
},
warning=function(cond) {
message(cond)
no_errors = FALSE
return(fighter_page)
})
# Most pages have the fight history as the 3rd table on the page, although for some
# it can be the 4th or 5th table. This checks which table is the fight history table.
tbl_num <- 3
loop = TRUE
while (loop == TRUE) {
error_check <- fighter_page %>%
html_nodes(paste0("section:nth-child(",tbl_num,") h2")) %>%
html_text()
# Links to opponent pages
if(!("Fight History - Pro" %in% error_check)){
tbl_num <- tbl_num + 1
} else {
loop = FALSE
}
}
# Opposing fighters' links
fighter_links <- fighter_page %>%
html_nodes(paste0("section:nth-child(",tbl_num,") td:nth-child(2) a")) %>%
html_attr("href")
# Track Fighter name
fighter_names <- fighter_page %>%
# use CSS selector to extract relevant entries from html
html_nodes(".nickname em , .fn") %>%
# turn the html output into simple text fields
html_text
# Using our same fight page from before
fighter_table <- fighter_page %>%
# extract fight history
html_nodes(paste0("section:nth-child(",tbl_num,") td")) %>%
# not a well-behaved table so it is extracted as strings
html_text() %>%
# wrap text to reform table
matrix(ncol = 6, byrow = T)
# Add column names from first entries of table
colnames(fighter_table) <- fighter_table[1,]
fighter_table <- fighter_table[-1,, drop = F]
fighter_table <- as.data.frame(fighter_table, stringsAsFactors = F)
fighter_table$Fighter1 <- fighter_names[[1]]
# Split Method/Referee columns
fighter_table$Referee <- html_text(html_nodes(
fighter_page, paste0("section:nth-child(",tbl_num,") td:nth-child(4) .sub_line"))) %>% na.omit()
fighter_table$Method_d <- sapply(fighter_table$`Method/Referee`,
function(x) gsub("N/A","",gsub('\\)(.*)','',
gsub('^(.*)\\(','',x))))
fighter_table$Method <- sapply(fighter_table$`Method/Referee`,
function(x) gsub("N/A","",gsub('\\(.*','',x)))
# Fix Date/Event column
fighter_table$Date <- html_text(html_nodes(
fighter_page, paste0("section:nth-child(",tbl_num,") td:nth-child(3) .sub_line"))) %>%
as.Date(format="%B / %d / %Y") %>% na.omit()
fighter_table$Event <- html_text(html_nodes(
fighter_page, paste0("section:nth-child(",tbl_num,") td:nth-child(3) a"))) %>% na.omit()
# Add both fighters' links
fighter_table$Link1 <- link
fighter_table$Link2 <- fighter_links
fighter_table <- fighter_table %>%
tbl_df() %>%
# reorder
select(Fighter1, Result, Fighter2=Fighter, Method, Method_d, R, Time,
Referee, Event, Date, Link1, Link2)
# Remove rows which are already in final table
fighter_table <- subset(fighter_table, !(Link2 %in% searched_links))
fights_table <- rbind(fights_table, fighter_table)
if (no_errors == TRUE) {
searched_links <- unique(append(searched_links, link))
links_to_search <- fighter_links[fighter_links != "javascript:void();"]
}
return(list("fights" = fights_table,
"searched" = data.frame(searched_links),
"toSearch" = links_to_search))
}
# Combines the scraped results
bind <- function(a, b) {
fights_table = rbind(a[[1]], b[[1]])
searched = rbind(a[[2]], b[[2]])
toSearch = append(a[[3]], b[[3]]) %>% setdiff(searched$searched_links)
return(list("fights"=fights_table, "searched"=searched, "toSearch"=toSearch))
}
while(length(fights_table$toSearch >= 1)) {
print(system.time({
pb <- txtProgressBar(max = length(head(fights_table[[3]], 100)), style = 3)
progress <- function(n) setTxtProgressBar(pb, n)
opts <- list(progress = progress)
fights_table2 <<- foreach(link=head(fights_table[[3]], 100), .combine='bind', .multicombine=TRUE,
.maxcombine=2, .export=c("link", "scrape"),
.options.snow = opts) %dopar% {
scrape(link)
}
fights_table <- bind(fights_table, fights_table2)
}))
rm(fights_table2)
}
while(length(fights_table$toSearch >= 1)) {
print(system.time({
pb <- txtProgressBar(max = length(head(fights_table[[3]], 100)), style = 3)
progress <- function(n) setTxtProgressBar(pb, n)
opts <- list(progress = progress)
fights_table2 <<- foreach(link2=head(fights_table[[3]], 100), .combine='bind', .multicombine=TRUE,
.maxcombine=2, .export=c("link", "scrape"),
.options.snow = opts) %dopar% {
scrape(link2)
}
fights_table <- bind(fights_table, fights_table2)
}))
rm(fights_table2)
}
# Start our search with Chael P. Sonnen. Can replace this with ANY fighter's Sherdog link.
link = "/fighter/Chael-Sonnen-4112"
while(length(fights_table$toSearch >= 1)) {
print(system.time({
pb <- txtProgressBar(max = length(head(fights_table[[3]], 100)), style = 3)
progress <- function(n) setTxtProgressBar(pb, n)
opts <- list(progress = progress)
fights_table2 <<- foreach(link2=head(fights_table[[3]], 100), .combine='bind', .multicombine=TRUE,
.maxcombine=2, .export=c("link", "scrape"),
.options.snow = opts) %dopar% {
scrape(link2)
}
fights_table <- bind(fights_table, fights_table2)
}))
rm(fights_table2)
}
stopCluster(cl)
rm(NumberOfCluster, opts, pb)
if (!require("rvest")) install.packages("rvest")
library(rvest)
if (!require("httr")) install.packages("httr")
library(httr)
if (!require("dplyr")) install.packages("dplyr")
library(dplyr)
if (!require("xml2")) install.packages("xml2")
library(xml2)
NumberOfCluster <- detectCores()
cl <- makeCluster(NumberOfCluster, outfile="log.txt")
registerDoSNOW(cl)
while(length(fights_table$toSearch >= 1)) {
print(system.time({
pb <- txtProgressBar(max = length(head(fights_table[[3]], 100)), style = 3)
progress <- function(n) setTxtProgressBar(pb, n)
opts <- list(progress = progress)
fights_table2 <<- foreach(link2=head(fights_table[[3]], 100), .combine='bind', .multicombine=TRUE,
.maxcombine=2, .export=c("link", "scrape"),
.options.snow = opts) %dopar% {
scrape(link2)
}
fights_table <- bind(fights_table, fights_table2)
}))
rm(fights_table2)
}
fights_table$fights
fights_table$fights$Link1 %>% unique %>% sort()
fights_table$fights$Link2 %>% unique %>% sort %>% head
saveRDS(fights_table, file = "fights_table.rds")
fights <- fights_table$fights
fights_table$searched %>% sort %>% head
fights_table$searched
fights_table$searched %>% head
fights_table$searched %>% head %>% sort()
fights_table$searched %>% head %>% sort(searched_links)
fights_table$searched %>% sort
fights %>% order_by(searched)
fights %>% arrange(searched)
class(fights)
arrange(fights, searched)
arrange(fights_table$searched, searched)
arrange(fights_table$searched, searched_links)
arrange(fights_table$searched, searched_links) %>% head
as.vector(fights_table[[2]])
as.vector(fights_table[[2]]) %>% class()
fights_table[[2]]$searched_links %>% sort %>% head
fights_table[[2]]$searched_links %>% as.character %>% sort %>% head
fights_table[[2]]$searched_links %>% as.character %>% sort %>% tail
fights$Method %>% unique() %>% sort()
View(fights)
fights$Method %>% table
fights$Method %>% table
head(fights$Referee)
head(fights$Referee) %in% head(fights$Method)
head(fights$Method)
fights$Referee %in% fights$Method
?grep
grep("josh", "kneejosh")
grepl("josh", "kneejosh")
grepl(fights$Method, fights$Method_d)
grep(fights$Method, fights$Method_d)
fights[4040,]
fights[4040,] %>% View
fights[grep(fights$Method, fights$Method_d)] %>% View
fights[grep(fights$Method, fights$Method_d),] %>% View
fights$Result %>% table
fights$R %>% table
gsub(fights$Referee, "", fights$Method)
View(gsub(fights$Referee, "", fights$Method))
gsub(fights$Referee, "", fights$Method) %>% table
install.packages("tidyr")
install.packages("tidyverse")
=======
k_vec = k_grid,
initial_ratings = 0) {
crossing(
testType = test_type, ratingType = rating_type
) %>%
mutate(
dataName = paste0("fights_k_", testType),
kVec = rep(list(k_vec), n()),
rateFunGenName = paste0(ratingType, "_fun_gen"),
winProbFunName = paste0(ratingType, "_win_prob"),
initialRatings = rep(list(initial_ratings), n()),
experimentData = pmap(
list(dataName, testType, kVec,
rateFunGenName, winProbFunName, initialRatings),
compute_goodness_wrap
)
) %>%
unnest(experimentData) %>%
select(testType, ratingType, k, goodness)
}
# Takes some time to run
fights_k_validation <- fights_k %>% filter(matchType != "test")
fights_k_test <- fights_k
experiment_tbl_fights <- do_experiment_fights()
?add_elo_ratings
source('~/GitHub/MMAscraper/ratings-4/add_ratings.R', echo=TRUE)
install.packages("comperank")
source('~/GitHub/MMAscraper/ratings-4/add_ratings.R', echo=TRUE)
source('~/GitHub/MMAscraper/ratings-4/add_ratings.R', echo=TRUE)
rankelo <- rank_elo(fights2, K=50, keep_rating = TRUE)
rankelo
rankelo %>% arrange(rating_elo)
rankelo %>% arrange(-rating_elo)
rankelo %>% arrange(-rating_elo) %>% View
fights2
elo %>% View()
rankelo %>% arrange(-rating_elo) %>% View
elo %>% View()
elo <- add_elo_ratings(fights2, K=100, initial_ratings = 1000)
rankelo <- rank_elo(fights2, K=100, keep_rating = TRUE)
View(rankelo)
######## Optimal K ########
# Function to split cases between "train", "validation", and "test" types
split_cases <- function(n, props = c(0.5, 0.25, 0.25)) {
breaks <- n * cumsum(head(props, -1)) / sum(props)
id_vec <- findInterval(seq_len(n), breaks, left.open = TRUE) + 1
c("train", "validation", "test")[id_vec]
}
fights_k <- fights2 %>%
mutate(matchtype = split_cases(n()))
# Grid for K factor
k_grid <- seq(50,200,10)
compute_goodness <- function(matches, test_type, k_vec, rate_fun_gen,
get_win_prob, initial_ratings = 0) {
cat("\n")
map_dfr(k_vec, function(cur_k) {
# Track execution
cat(cur_k, " ")
matches %>%
arrange(game) %>%
add_iterative_ratings(
rate_fun = rate_fun_gen(cur_k), initial_ratings = initial_ratings
) %>%
left_join(y = matches %>% select(game, matchType), by = "game") %>%
filter(matchType %in% test_type) %>%
mutate(
# Number of frames needed to win in a match
framesToWin = pmax(score1, score2),
# Probability of player 1 winning a match with `frame_to_win` frames
# needed to win.
winProb = get_win_prob(
rating1 = rating1Before, rating2 = rating2Before,
frames_to_win = framesToWin
),
result = get_match_result(score1, score2),
squareError = (result - winProb)^2
) %>%
summarise(goodness = sqrt(mean(squareError)))
}) %>%
mutate(k = k_vec) %>%
select(k, goodness)
}
#' A wrapper for `compute_goodness()` to be used with design matrix data.
compute_goodness_wrap <- function(matches_name, test_type, k_vec,
rate_fun_gen_name, win_prob_fun_name,
initial_ratings = 0) {
matches_tbl <- get(matches_name)
rate_fun_gen <- get(rate_fun_gen_name)
get_win_prob <- get(win_prob_fun_name)
compute_goodness(
matches_tbl, test_type, k_vec, rate_fun_gen, get_win_prob, initial_ratings
)
}
fights_k_validation <- fights_k %>% filter(matchType != "test")
fights_k_test <- fights_k
# Grid for K factor
k_grid <- seq(50,200,10)
compute_goodness <- function(matches, test_type, k_vec, rate_fun_gen,
get_win_prob, initial_ratings = 0) {
cat("\n")
map_dfr(k_vec, function(cur_k) {
# Track execution
cat(cur_k, " ")
matches %>%
arrange(game) %>%
add_iterative_ratings(
rate_fun = rate_fun_gen(cur_k), initial_ratings = initial_ratings
) %>%
left_join(y = matches %>% select(game, matchType), by = "game") %>%
filter(matchType %in% test_type) %>%
mutate(
# Number of frames needed to win in a match
framesToWin = pmax(score1, score2),
# Probability of player 1 winning a match with `frame_to_win` frames
# needed to win.
winProb = get_win_prob(
rating1 = rating1Before, rating2 = rating2Before,
frames_to_win = framesToWin
),
result = get_match_result(score1, score2),
squareError = (result - winProb)^2
) %>%
summarise(goodness = sqrt(mean(squareError)))
}) %>%
mutate(k = k_vec) %>%
select(k, goodness)
}
#' A wrapper for `compute_goodness()` to be used with design matrix data.
compute_goodness_wrap <- function(matches_name, test_type, k_vec,
rate_fun_gen_name, win_prob_fun_name,
initial_ratings = 0) {
matches_tbl <- get(matches_name)
rate_fun_gen <- get(rate_fun_gen_name)
get_win_prob <- get(win_prob_fun_name)
compute_goodness(
matches_tbl, test_type, k_vec, rate_fun_gen, get_win_prob, initial_ratings
)
}
do_experiment <- function(test_type = c("validation", "test"),
rating_type = "elo",
k_vec = k_grid,
initial_ratings = 0) {
crossing(
testType = test_type
) %>%
mutate(
dataName = paste0("fights_k_", testType),
kVec = rep(list(k_vec), n()),
rateFunGenName = paste0(ratingType, "_fun_gen"),
winProbFunName = paste0(ratingType, "_win_prob"),
initialRatings = rep(list(initial_ratings), n()),
experimentData = pmap(
list(dataName, testType, kVec,
rateFunGenName, winProbFunName, initialRatings),
compute_goodness_wrap
)
) %>%
unnest(experimentData) %>%
select(testType, ratingType, k, goodness)
}
experiment_tbl <- do_experiment()
do_experiment <- function(test_type = c("validation", "test"),
rating_type = "elo",
k_vec = k_grid,
initial_ratings = 0) {
crossing(
testType = test_type, ratingType = rating_type
) %>%
mutate(
dataName = paste0("fights_k_", testType),
kVec = rep(list(k_vec), n()),
rateFunGenName = paste0(ratingType, "_fun_gen"),
winProbFunName = paste0(ratingType, "_win_prob"),
initialRatings = rep(list(initial_ratings), n()),
experimentData = pmap(
list(dataName, testType, kVec,
rateFunGenName, winProbFunName, initialRatings),
compute_goodness_wrap
)
) %>%
unnest(experimentData) %>%
select(testType, ratingType, k, goodness)
}
experiment_tbl <- do_experiment()
######## Optimal K ########
elo_win_prob <- function(rating1, rating2, ksi = 400, ...) {
norm_rating_diff <- (rating2 - rating1) / ksi
1 / (1 + 10^norm_rating_diff)
}
#' @return A rating function for Elo model that can be supplied to
#'   `comperank::add_iterative_ratings()`.
elo_fun_gen <- function(K, ksi = 400) {
function(rating1, score1, rating2, score2) {
comperank::elo(rating1, score1, rating2, score2, K = K, ksi = ksi)[1, ]
}
}
do_experiment <- function(test_type = c("validation", "test"),
rating_type = "elo",
k_vec = k_grid,
initial_ratings = 0) {
crossing(
testType = test_type, ratingType = rating_type
) %>%
mutate(
dataName = paste0("fights_k_", testType),
kVec = rep(list(k_vec), n()),
rateFunGenName = paste0(ratingType, "_fun_gen"),
winProbFunName = paste0(ratingType, "_win_prob"),
initialRatings = rep(list(initial_ratings), n()),
experimentData = pmap(
list(dataName, testType, kVec,
rateFunGenName, winProbFunName, initialRatings),
compute_goodness_wrap
)
) %>%
unnest(experimentData) %>%
select(testType, ratingType, k, goodness)
}
experiment_tbl <- do_experiment()
######## Optimal K ########
elo_win_prob <- function(rating1, rating2, ksi = 400, ...) {
norm_rating_diff <- (rating2 - rating1) / ksi
1 / (1 + 10^norm_rating_diff)
}
elo_fun_gen <- function(K, ksi = 400) {
function(rating1, score1, rating2, score2) {
comperank::elo(rating1, score1, rating2, score2, K = K, ksi = ksi)[1, ]
}
}
# Function to split cases between "train", "validation", and "test" types
split_cases <- function(n, props = c(0.5, 0.25, 0.25)) {
breaks <- n * cumsum(head(props, -1)) / sum(props)
id_vec <- findInterval(seq_len(n), breaks, left.open = TRUE) + 1
c("train", "validation", "test")[id_vec]
}
fights_k <- fights2 %>%
mutate(matchType = split_cases(n()))
fights_k_validation <- fights_k %>% filter(matchType != "test")
fights_k_test <- fights_k
# Grid for K factor
k_grid <- seq(50,200,10)
compute_goodness <- function(matches, test_type, k_vec, rate_fun_gen,
get_win_prob, initial_ratings = 0) {
cat("\n")
map_dfr(k_vec, function(cur_k) {
# Track execution
cat(cur_k, " ")
matches %>%
arrange(game) %>%
add_iterative_ratings(
rate_fun = rate_fun_gen(cur_k), initial_ratings = initial_ratings
) %>%
left_join(y = matches %>% select(game, matchType), by = "game") %>%
filter(matchType %in% test_type) %>%
mutate(
# Number of frames needed to win in a match
framesToWin = pmax(score1, score2),
# Probability of player 1 winning a match with `frame_to_win` frames
# needed to win.
winProb = get_win_prob(
rating1 = rating1Before, rating2 = rating2Before,
frames_to_win = framesToWin
),
result = get_match_result(score1, score2),
squareError = (result - winProb)^2
) %>%
summarise(goodness = sqrt(mean(squareError)))
}) %>%
mutate(k = k_vec) %>%
select(k, goodness)
}
#' A wrapper for `compute_goodness()` to be used with design matrix data.
compute_goodness_wrap <- function(matches_name, test_type, k_vec,
rate_fun_gen_name, win_prob_fun_name,
initial_ratings = 0) {
matches_tbl <- get(matches_name)
rate_fun_gen <- get(rate_fun_gen_name)
get_win_prob <- get(win_prob_fun_name)
compute_goodness(
matches_tbl, test_type, k_vec, rate_fun_gen, get_win_prob, initial_ratings
)
}
do_experiment <- function(test_type = c("validation", "test"),
rating_type = "elo",
k_vec = k_grid,
initial_ratings = 0) {
crossing(
testType = test_type, ratingType = rating_type
) %>%
mutate(
dataName = paste0("fights_k_", testType),
kVec = rep(list(k_vec), n()),
rateFunGenName = paste0(ratingType, "_fun_gen"),
winProbFunName = paste0(ratingType, "_win_prob"),
initialRatings = rep(list(initial_ratings), n()),
experimentData = pmap(
list(dataName, testType, kVec,
rateFunGenName, winProbFunName, initialRatings),
compute_goodness_wrap
)
) %>%
unnest(experimentData) %>%
select(testType, ratingType, k, goodness)
}
experiment_tbl <- do_experiment()
elo_win_prob <- function(rating1, rating2, ksi = 400, ...) {
norm_rating_diff <- (rating2 - rating1) / ksi
1 / (1 + 10^norm_rating_diff)
}
elo_fun_gen <- function(K, ksi = 400) {
function(rating1, score1, rating2, score2) {
comperank::elo(rating1, score1, rating2, score2, K = K, ksi = ksi)[1, ]
}
}
get_match_result <- function(score1, score2) {
# There are no ties in snooker but this handles general case
near_score <- dplyr::near(score1, score2)
dplyr::if_else(near_score, 0.5, as.numeric(score1 > score2))
}
# Function to split cases between "train", "validation", and "test" types
split_cases <- function(n, props = c(0.5, 0.25, 0.25)) {
breaks <- n * cumsum(head(props, -1)) / sum(props)
id_vec <- findInterval(seq_len(n), breaks, left.open = TRUE) + 1
c("train", "validation", "test")[id_vec]
}
fights_k <- fights2 %>%
mutate(matchType = split_cases(n()))
fights_k_validation <- fights_k %>% filter(matchType != "test")
fights_k_test <- fights_k
# Grid for K factor
k_grid <- seq(50,200,10)
compute_goodness <- function(matches, test_type, k_vec, rate_fun_gen,
get_win_prob, initial_ratings = 0) {
cat("\n")
map_dfr(k_vec, function(cur_k) {
# Track execution
cat(cur_k, " ")
matches %>%
arrange(game) %>%
add_iterative_ratings(
rate_fun = rate_fun_gen(cur_k), initial_ratings = initial_ratings
) %>%
left_join(y = matches %>% select(game, matchType), by = "game") %>%
filter(matchType %in% test_type) %>%
mutate(
# Number of frames needed to win in a match
framesToWin = pmax(score1, score2),
# Probability of player 1 winning a match with `frame_to_win` frames
# needed to win.
winProb = get_win_prob(
rating1 = rating1Before, rating2 = rating2Before,
frames_to_win = framesToWin
),
result = get_match_result(score1, score2),
squareError = (result - winProb)^2
) %>%
summarise(goodness = sqrt(mean(squareError)))
}) %>%
mutate(k = k_vec) %>%
select(k, goodness)
}
#' A wrapper for `compute_goodness()` to be used with design matrix data.
compute_goodness_wrap <- function(matches_name, test_type, k_vec,
rate_fun_gen_name, win_prob_fun_name,
initial_ratings = 0) {
matches_tbl <- get(matches_name)
rate_fun_gen <- get(rate_fun_gen_name)
get_win_prob <- get(win_prob_fun_name)
compute_goodness(
matches_tbl, test_type, k_vec, rate_fun_gen, get_win_prob, initial_ratings
)
}
do_experiment <- function(test_type = c("validation", "test"),
rating_type = "elo",
k_vec = k_grid,
initial_ratings = 0) {
crossing(
testType = test_type, ratingType = rating_type
) %>%
mutate(
dataName = paste0("fights_k_", testType),
kVec = rep(list(k_vec), n()),
rateFunGenName = paste0(ratingType, "_fun_gen"),
winProbFunName = paste0(ratingType, "_win_prob"),
initialRatings = rep(list(initial_ratings), n()),
experimentData = pmap(
list(dataName, testType, kVec,
rateFunGenName, winProbFunName, initialRatings),
compute_goodness_wrap
)
) %>%
unnest(experimentData) %>%
select(testType, ratingType, k, goodness)
}
experiment_tbl <- do_experiment()
experiment_tbl
cap_first <- function(x) {
paste0(toupper(substring(x, 1, 1)), substring(x, 2))
}
plot_data <- experiment_tbl %>%
unite(group, ratingType) %>%
mutate(
testType = cap_first(testType),
groupName = recode(
group, elo = "Elo"
),
# Ensure preferred order. This is needed because sorting of strings will
# give "Elo, all matches", "EloBeta, all matches", "EloBeta, official
# matches", and "Elo, official matches" as, apperently, non-letters are
# ignored while sorting.
groupName = factor(groupName, levels = unique(groupName))
)
compute_optimal_k <- . %>% group_by(testType, groupName) %>%
slice(which.min(goodness)) %>%
ungroup()
compute_k_labels <- . %>% compute_optimal_k() %>%
mutate(label = paste0("K = ", k)) %>%
group_by(groupName) %>%
# If optimal K within future facet is on the right, it needs a little
# adjustment to the right. If on the left - full and a little adjustment to
# the left.
mutate(hjust = - (k == max(k)) * 1.1 + 1.05) %>%
ungroup()
plot_experiment_results <- function(results_tbl) {
ggplot(results_tbl) +
geom_hline(
yintercept = 0.5, colour = "#AA5555", size = 0.5, linetype = "dotted"
) +
geom_line(aes(k, goodness, colour = testType)) +
geom_vline(
data = compute_optimal_k,
mapping = aes(xintercept = k, colour = testType),
linetype = "dashed", show.legend = FALSE
) +
geom_text(
data = compute_k_labels,
mapping = aes(k, Inf, label = label, hjust = hjust),
vjust = 1.2
) +
facet_wrap(~ groupName) +
scale_colour_manual(
values = c(Validation = "#377EB8", Test = "#FF7F00"),
guide = guide_legend(
title = "Experiment", reverse = TRUE,
override.aes = list(size = 4)
)
) +
labs(
x = "K factor", y = "Goodness of fit (RMSE)",
title = "Best goodness of fit of Elo",
subtitle = paste0(
'All optimal K values from test experiment (with longer "warm up") are',
' lower than from validation experiment.'
)
) +
theme(title = element_text(size = 14), strip.text = element_text(size = 12))
}
plot_experiment_results(plot_data)
compute_k_labels()
compute_k_labels(plot_data)
elo <- add_elo_ratings(fights2, K=150, initial_ratings = 1000)
rankelo <- rank_elo(fights2, K=150, keep_rating = TRUE)
elo
View(rankelo)
View(elo)
rankelo <- rank_elo(fights2, K=150, keep_rating = TRUE, initial_ratings = 1000)
View(rankelo)
View(elo)
fights %>% filter(match_id == 32937)
filter %>% filter(method == "DQ") %>% table
filter %>% filter(method == "DQ")
fights %>% filter(method == "DQ")
fights %>% filter(Method == "DQ")
fights %>% filter(Method == "DQ") %>% table()
fights %>% filter(Method == "DQ") %>% count()
debug(add_elo_ratings)
elo <- add_elo_ratings(fights2, K=150, initial_ratings = 1000)
library(comperank)
library(tidyverse)
fights <- readRDS(file = "~/GitHub/MMAscraper/records-3/fights_records.rds")
fights2 <- fights %>%
filter(Result %in% c("win", "draw")) %>%
mutate(score1 = ifelse(Result == "win", 1, 0.5),
score2 = ifelse(Result == "win", 0, 0.5)) %>%
select(game = match_id, player1 = Link1, score1, player2 = Link2, score2)
fights2 <- as_widecr(fights2)
debug(add_elo_ratings)
elo <- add_elo_ratings(fights2, K=150, initial_ratings = 1000)
elo <- add_elo_ratings(fights2, K=150, initial_ratings = 1000)
cr_data
rate_fun
View(cr)
View(ratings)
elo <- add_elo_ratings(fights2, K=150, initial_ratings = 1000)
lhs
debug(compute_iterative_ratings)
elo <- add_elo_ratings(fights2, K=150, initial_ratings = 1000)
debug(compute_iterative_ratings)
elo <- add_elo_ratings(fights2, K=150, initial_ratings = 1000)
debug(compute_iterative_ratings)
elo <- add_elo_ratings(fights2, K=150, initial_ratings = 1000)
elo <- add_elo_ratings(fights2, K=150, initial_ratings = 1000)
sn
debug(compute_iterative_ratings)
ls()
comperank:::compute_iterative_ratings()
comperank:::compute_iterative_ratings()
.Call("_comperank_compute_iterative_ratings", PACKAGE = "comperank",
rate_fun, player1_id, score1, player2_id, score2, initial_ratings)
rowMeans
comperank:::compute_iterative_ratings() %>% showMethods
undebug(compute_iterative_ratings)
>>>>>>> df5dd2323bd8e258898cbc963f0fa364cc40ef09
